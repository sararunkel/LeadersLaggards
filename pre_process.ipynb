{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "#Environment -- geopy\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import linregress\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from category_encoders import GLMMEncoder\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.stats.api as sms\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.compat import lzip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xls = pd.ExcelFile('USA_NO2_MSA_GDP.xlsx')\n",
    "msa = pd.read_excel(xls, 'MSA_2010')\n",
    "#pop_2019 = pd.read_excel(xls, '2019')\n",
    "pop_2010 =pd.read_excel(xls, '2010')\n",
    "us = pd.read_excel(xls,'US_13')\n",
    "m_19=pd.read_excel(xls,'Sheet4')\n",
    "full = pd.read_excel(xls, 'usa')\n",
    "\n",
    "msa_full =msa.merge(m_19[['Merge',2019]],how='left',left_on='Label',right_on='Merge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select just the 2019 and 2010 years for of the US dataset\n",
    "\n",
    "us_19= full.query(\"Year ==2019\").copy().drop_duplicates().set_index('CityCountry')\n",
    "us_10= full.query(\"Year ==2010\").copy().drop_duplicates().set_index('CityCountry')\n",
    "\n",
    "us_19['Slope']= full.groupby('CityCountry').apply(lambda v: linregress(v.Year, v.NO2)[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NW = ['WA','OR','ID']\n",
    "SW=['CA','NV','UT','NM','AZ','CO']\n",
    "NGP=['MT','WY','ND','SD','NE']\n",
    "SGP=['TX','OK','KS']\n",
    "SE=['LA','AR','AL','FL','MS','TN','KY','GA','SC','NC','DC','VA']\n",
    "NE = ['WV','PA','NY','MD','DE','NH','VT','ME','MA','RI','NJ','CT']\n",
    "MW =['WI','MO','MN','MI','IN','IL','IA','OH']\n",
    "Other = ['AK','HI']\n",
    "\n",
    "rdict = {'NW':NW,'SW':SW,'NGP':NGP,'SGP':SGP,'SE':SE,'NE':NE,'MW':MW,'Other':Other}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename values to merge into single DC and merge with GDP\n",
    "merge= us_19.reset_index().merge(gdp.reset_index(),how='left')\n",
    "merge.set_index('CityCountry',inplace=True)\n",
    "merge['Base_GDP'] =merge[2010]\n",
    "merge['GDP'] =merge[2019]\n",
    "merge['Base_NO2']=us_10['NO2']\n",
    "merge['Base_Population']=us_10['Population']\n",
    "merge['NO2T']=np.log(merge.NO2)\n",
    "merge['BaseT']=np.sqrt(merge.Base_NO2)\n",
    "merge['LogGDP']=np.log(merge[2010])\n",
    "gdp = pd.read_excel(xls,'GDP')\n",
    "\n",
    "gdp.set_index('CityCountry', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge['Region']=''\n",
    "for i in rdict:\n",
    "    filter = merge[\"State\"].isin(rdict[i])\n",
    "    merge['Region'].where(~filter,i,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Create metrics from merged datafile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Percapita metric\n",
    "\n",
    "pcap=msa_full.merge(gdp,how='right',on='CityCountry')\n",
    "pcap['Base_PerCapita']=pcap['2010_y']/pcap['2010_x']\n",
    "pcap['PerCapita']=pcap['2019_y']/pcap['2019_x']\n",
    "pcap.set_index('CityCountry',inplace=True)\n",
    "\n",
    "merge['PerCapita']=pcap['PerCapita']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Percent change metric\n",
    "merge['ConcPercChange']=100*(merge.NO2-merge.Base_NO2)/merge.Base_NO2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y= plot['NO2T']\n",
    "X = plot[['BaseT','LogGDP','Region']]\n",
    "enc = GLMMEncoder(cols=['Region']).fit(X,y)\n",
    "numeric_dataset = enc.transform(X)\n",
    "numeric_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = sm.add_constant(numeric_dataset)\n",
    "est = sm.OLS(y, X2)\n",
    "est2 = est.fit()\n",
    "est2.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats.mstats import zscore\n",
    "zx =zscore(numeric_dataset)\n",
    "zy = zscore(y)\n",
    "#zx2 = sm.add_constant(zx)\n",
    "model = sm.OLS(zy,zx)\n",
    "results = model.fit()\n",
    "results.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "def calculate_stats(dataframe):\n",
    "    dataframe['Predicted']=np.exp(predicted)\n",
    "    dataframe['Actual']= np.exp(actual)\n",
    "    dataframe['pc_dif']=100*(dataframe.Actual-dataframe.Predicted)/dataframe.Actual\n",
    "    dataframe['abs_dif']= dataframe['pc_dif'].abs()\n",
    "    dataframe['Residuals']= dataframe.Actual-dataframe.Predicted\n",
    "\n",
    "\n",
    "regr = linear_model.LinearRegression(fit_intercept=True)\n",
    "regr.fit(numeric_dataset, y)\n",
    "coef = regr.coef_\n",
    "#coef = np.polyfit(x, y, z, 1)\n",
    "inter = regr.intercept_\n",
    "actual = []\n",
    "predicted = []\n",
    "for ind in range(len(numeric_dataset)):\n",
    "    actual.append(y.iloc[ind])\n",
    "    predicted.append(sum([coef[i]*numeric_dataset.iloc[ind][i] for i in range(len(coef))])+inter)\n",
    "    \n",
    "\n",
    "##predicted is predicted NO2/capita\n",
    "calculate_stats(merge)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dictionary to conver the US state to its abbreviation for merging\n",
    "us_state_to_abbrev = {\n",
    "    \"Alabama\": \"AL\",\n",
    "    \"Alaska\": \"AK\",\n",
    "    \"Arizona\": \"AZ\",\n",
    "    \"Arkansas\": \"AR\",\n",
    "    \"California\": \"CA\",\n",
    "    \"Colorado\": \"CO\",\n",
    "    \"Connecticut\": \"CT\",\n",
    "    \"Delaware\": \"DE\",\n",
    "    \"Florida\": \"FL\",\n",
    "    \"Georgia\": \"GA\",\n",
    "    \"Hawaii\": \"HI\",\n",
    "    \"Idaho\": \"ID\",\n",
    "    \"Illinois\": \"IL\",\n",
    "    \"Indiana\": \"IN\",\n",
    "    \"Iowa\": \"IA\",\n",
    "    \"Kansas\": \"KS\",\n",
    "    \"Kentucky\": \"KY\",\n",
    "    \"Louisiana\": \"LA\",\n",
    "    \"Maine\": \"ME\",\n",
    "    \"Maryland\": \"MD\",\n",
    "    \"Massachusetts\": \"MA\",\n",
    "    \"Michigan\": \"MI\",\n",
    "    \"Minnesota\": \"MN\",\n",
    "    \"Mississippi\": \"MS\",\n",
    "    \"Missouri\": \"MO\",\n",
    "    \"Montana\": \"MT\",\n",
    "    \"Nebraska\": \"NE\",\n",
    "    \"Nevada\": \"NV\",\n",
    "    \"New Hampshire\": \"NH\",\n",
    "    \"New Jersey\": \"NJ\",\n",
    "    \"New Mexico\": \"NM\",\n",
    "    \"New York\": \"NY\",\n",
    "    \"North Carolina\": \"NC\",\n",
    "    \"North Dakota\": \"ND\",\n",
    "    \"Ohio\": \"OH\",\n",
    "    \"Oklahoma\": \"OK\",\n",
    "    \"Oregon\": \"OR\",\n",
    "    \"Pennsylvania\": \"PA\",\n",
    "    \"Rhode Island\": \"RI\",\n",
    "    \"South Carolina\": \"SC\",\n",
    "    \"South Dakota\": \"SD\",\n",
    "    \"Tennessee\": \"TN\",\n",
    "    \"Texas\": \"TX\",\n",
    "    \"Utah\": \"UT\",\n",
    "    \"Vermont\": \"VT\",\n",
    "    \"Virginia\": \"VA\",\n",
    "    \"Washington\": \"WA\",\n",
    "    \"West Virginia\": \"WV\",\n",
    "    \"Wisconsin\": \"WI\",\n",
    "    \"Wyoming\": \"WY\",\n",
    "    \"District of Columbia\": \"DC\",\n",
    "    \"American Samoa\": \"AS\",\n",
    "    \"Guam\": \"GU\",\n",
    "    \"Northern Mariana Islands\": \"MP\",\n",
    "    \"Puerto Rico\": \"PR\",\n",
    "    \"United States Minor Outlying Islands\": \"UM\",\n",
    "    \"U.S. Virgin Islands\": \"VI\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asthma= pd.read_csv('asthmaincidence/IHME-GBD_2019_DATA-bd31445e-1.csv')\n",
    "asthma['location_name']=asthma.location_name.replace(us_state_to_abbrev)\n",
    "asthma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample air quality data (replace this with your own data)\n",
    "plot = merge\n",
    "\n",
    "# Define weights for each metric (adjust these weights as needed)\n",
    "metrics = {'ConcPercChange':'ConcChange','Slope':'slope','Residuals':'resid'}\n",
    "\n",
    "# Normalize the data using min-max scaling\n",
    "for metric in metrics:\n",
    "    min_val = plot[metric].min()\n",
    "    max_val = plot[metric].max()\n",
    "    plot[metrics[metric] + '_Score'] = (plot[metric] - min_val) / (max_val - min_val)\n",
    "\n",
    "# Calculate scores for each city\n",
    "\n",
    "# Calculate total scores for each city\n",
    "plot['Total_Score'] = plot[['ConcChange_Score', 'slope_Score','resid_Score']].sum(axis=1)/3\n",
    "\n",
    "# Rank cities based on total scores\n",
    "plot = plot.sort_values(by='Total_Score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot=plot.merge(asthma.query('year==2010')[['location_name','val']],how='left',left_on='State',right_on='location_name').drop_duplicates().rename(columns={'val':'asthma_2010'})\n",
    "plot=plot.merge(asthma.query('year==2019')[['location_name','val']],how='left',left_on='State',right_on='location_name').drop_duplicates().rename(columns={'val':'asthma_2019'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot['ActualAF']=plot.Actual.apply(calculate_af)\n",
    "plot['PredictedAF']=plot.Predicted.apply(calculate_af)\n",
    "plot['BaseAF'] =plot.Base_NO2.apply(calculate_af)\n",
    "plot['Actual_Cases'] = plot.ActualAF*(plot.asthma_2019/1e5)*plot.Pop_ped\n",
    "plot['Predicted_Cases'] = plot.PredictedAF*(plot.asthma_2019/1e5)*plot.Pop_ped\n",
    "plot['Base_Cases'] = plot.BaseAF*(plot.asthma_2010/1e5)*plot.Base_Pop_ped\n",
    "plot['Cases_Residual']=plot.Actual_Cases-plot.Predicted_Cases\n",
    "plot['Rates_Residual'] = plot['Cases_Residual']/(plot.Pop_ped/1e5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.to_csv('Inputs/us_asthmaprediction.csv')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
